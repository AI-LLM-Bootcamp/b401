{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Prompts and Prompt Templates\n",
    "* Introduce programming in your conversation with the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c759d27a-94f3-4141-945d-065f2095bffd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Intro\n",
    "* Input: the prompt we send to the LLM.\n",
    "* Output: the response from the LLM.\n",
    "* We can switch LLMs and use several different LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981f91b-686d-401c-a872-65487f93b46e",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* LLMs.\n",
    "* Prompts and Prompt Templates.\n",
    "* Types of prompts: Zero Shot and Few Shot(s) Prompt.\n",
    "* Serialization: Saving and Loading Prompts.\n",
    "* Parsing Outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332b6e9-8164-4859-879c-f021a4dfd69d",
   "metadata": {},
   "source": [
    "## LangChain divides LLMs in two types\n",
    "1. LLM Model: text-completion model.\n",
    "2. Chat Model: converses with a sequence of messages and can have a particular role defined (system prompt). This type has become the most used in LangChain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42a3ca-fc4d-4b91-b3bc-a7304ec4d5f8",
   "metadata": {},
   "source": [
    "## See the differences\n",
    "* Even when sometimes the LangChain documentation can be confusing about it, the fact is that text-completion models and Chat models are both LLMs.\n",
    "* But, as you can see in this [playground](https://platform.openai.com/playground/chat?models=gpt-4o), they have some significant differences. See that the chat models in LangChain have system messages, human messages (called \"user messages\" by OpenAI) and AI messages (called \"Assitant Messages\" by OpenAI).\n",
    "* Since the launch of chatGPT, the Chat Model is the most popular LLM type and is used in most LLM apps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f9501-fa9e-4830-95e2-537dff951cf1",
   "metadata": {},
   "source": [
    "## List of LLMs that can work with LangChain\n",
    "* See the list [here](https://python.langchain.com/v0.1/docs/integrations/llms/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80616acf-ae85-4226-ba19-dbbbb9d4796f",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a6725-81b3-4ea3-b39a-eb8f2ded91a2",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 003-prompt-templates.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **003-prompt-templates**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2746c97-9fa5-481c-8333-21de1504a087",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ba351-2cfb-4b93-9c79-3c1100e2e291",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eaf7e9-acf2-4729-b54c-a8fb6ad2ae1a",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a10870-432e-4818-aa5e-6be24c579d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa888f7-3718-4829-8645-30acb43db51f",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d5b71-b26a-4cd5-9765-019077a67141",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1d17b-6d15-423b-b554-26d6d977ca27",
   "metadata": {},
   "source": [
    "## LLM Model\n",
    "* The trend before the launch of chatGPT-4.\n",
    "* See LangChain documentation about LLM Models [here](https://python.langchain.com/v0.1/docs/modules/model_io/llms/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92628f2-62e8-436c-92d4-e849de7744ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b14d27c3-0b1b-4b11-a883-8da2734f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f91601-8594-41d3-9316-d51791fc54e8",
   "metadata": {},
   "source": [
    "## Prompts and Prompt Templates\n",
    "A **prompt** is the input we provide to one language model. This input will guide the way the language model will respond.\n",
    "There are many types of prompts:\n",
    "* Plain instructions.\n",
    "* Instructions with a few examples (few-shot examples).\n",
    "* Specific context and questions appropiate for a given task.\n",
    "* Etc.\n",
    "* See the LangChain documentation about prompts [here](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/).\n",
    "\n",
    "**Prompt templates** are pre-defined prompt recipes that usually need some extra pieces to be complete. These extra pieces are variables that the user will provide.\n",
    "* Prompt templates: when we want to use sophisticated prompts with variables and other elements. A prompt template may include:\n",
    "    * instructions,\n",
    "    * few-shot examples,\n",
    "    * and specific context and questions appropriate for a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5383c7e-7e62-46d0-8bef-17ff45a88495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nOne curious story about the Kennedy family involves a supposed curse that has followed them for generations. It is said that the curse originated with JFK's grandfather, John F. Fitzgerald, who was known for his womanizing ways and was rumored to have made a deal with the devil for political success.\\n\\nThe curse continued with JFK's father, Joseph P. Kennedy, who was involved in various scandals and controversies, including his alleged involvement in bootlegging during Prohibition. He also famously predicted that three of his sons would die young, which unfortunately came true with the assassinations of JFK, Robert F. Kennedy, and John F. Kennedy Jr.\\n\\nThe curse seemed to extend to JFK's children as well. His daughter, Caroline Kennedy, was involved in a skiing accident that left her with a severe concussion. His son, John F. Kennedy Jr., died in a plane crash along with his wife and sister-in-law. And his other son, Patrick Kennedy, was born prematurely and died just two days later.\\n\\nEven JFK's grandchildren have not been spared from the curse. One of his grandsons, John F. Kennedy III, was arrested for disorderly conduct and resisting arrest, and another grandson, William Kennedy Smith, was accused of rape.\\n\\nWhile some may dismiss the curse as\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} story about {topic}.\"\n",
    ")\n",
    "\n",
    "llmModelPrompt = prompt_template.format(\n",
    "    adjective=\"curious\", \n",
    "    topic=\"the Kennedy family\"\n",
    ")\n",
    "\n",
    "llmModel.invoke(llmModelPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb7dbcd-524c-4acc-9b65-0b209a170ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an {profession} expert on {topic}.\"),\n",
    "        (\"human\", \"Hello, Mr. {profession}, can you please answer a question?\"),\n",
    "        (\"ai\", \"Sure!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession=\"Historian\",\n",
    "    topic=\"The Kennedy family\",\n",
    "    user_input=\"How many grandchildren had Joseph P. Kennedy?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7585be48-9a19-43ab-a275-8ef6a04246a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Joseph P. Kennedy, Sr. and his wife Rose Fitzgerald Kennedy had a total of nine grandchildren. Their children were John F. Kennedy, Robert F. Kennedy, Ted Kennedy, Eunice Kennedy Shriver, Patricia Kennedy Lawford, Jean Kennedy Smith, and Rosemary Kennedy.', response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 55, 'total_tokens': 112}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-970c06fd-afd3-4b21-8e9e-f51e97ab6511-0', usage_metadata={'input_tokens': 55, 'output_tokens': 57, 'total_tokens': 112})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1373ca0b-342f-4ac6-a697-5e2ad30bfa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Joseph P. Kennedy, Sr. and his wife Rose Fitzgerald Kennedy had a total of nine grandchildren. Their children were John F. Kennedy, Robert F. Kennedy, Ted Kennedy, Eunice Kennedy Shriver, Patricia Kennedy Lawford, Jean Kennedy Smith, and Rosemary Kennedy.' response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 55, 'total_tokens': 112}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-970c06fd-afd3-4b21-8e9e-f51e97ab6511-0' usage_metadata={'input_tokens': 55, 'output_tokens': 57, 'total_tokens': 112}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f6a5e25-e177-4d7a-ba29-6834a6a8152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy, Sr. and his wife Rose Fitzgerald Kennedy had a total of nine grandchildren. Their children were John F. Kennedy, Robert F. Kennedy, Ted Kennedy, Eunice Kennedy Shriver, Patricia Kennedy Lawford, Jean Kennedy Smith, and Rosemary Kennedy.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d770b4-80c5-49a6-a925-de3a800d19f2",
   "metadata": {},
   "source": [
    "#### Old way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6dafd17-47a2-4169-992e-76ffb9702d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are an Historian expert on the Kennedy family.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    user_input=\"Name the children and grandchildren of Joseph P. Kennedy?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a4d5a5a-c3a3-48be-8b31-40b0881faa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy and his wife Rose Fitzgerald Kennedy had nine children:\n",
      "\n",
      "1. Joseph P. Kennedy Jr.\n",
      "2. John F. Kennedy\n",
      "3. Rosemary Kennedy\n",
      "4. Kathleen Kennedy\n",
      "5. Eunice Kennedy\n",
      "6. Patricia Kennedy\n",
      "7. Robert F. Kennedy\n",
      "8. Jean Kennedy\n",
      "9. Edward M. Kennedy\n",
      "\n",
      "The grandchildren of Joseph P. Kennedy include Caroline Kennedy (daughter of John F. Kennedy), Maria Shriver (daughter of Eunice Kennedy), and Robert F. Kennedy Jr. (son of Robert F. Kennedy), among others.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b510dd0-33b7-4737-aef2-c52a1e8bbf41",
   "metadata": {},
   "source": [
    "#### What is the full potential of ChatPromptTemplate?\n",
    "* Check the [corresponding page](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) in the LangChain API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b9539",
   "metadata": {},
   "source": [
    "## Basic prompting strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a985bbc",
   "metadata": {},
   "source": [
    "* Zero Shot Prompt: \"Classify the sentiment of this review: ...\"\n",
    "* Few Shot Prompt: \"Classify the sentiment of this review based on these examples: ...\"\n",
    "* Chain Of Thought Prompt: \"Classify the sentiment of this review based on these examples and explanations of the reasoning behind: ...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649bc16",
   "metadata": {},
   "source": [
    "## Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c285419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3ae0df0-44fe-4fd2-89a5-bac45a84e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"¡adiós!\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a50eb-dfe4-4d08-802e-c3dbc40a3444",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-connect-llms.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 003-prompt-templates.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d7c2f-57ed-43f5-b6ed-77c54243c069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
